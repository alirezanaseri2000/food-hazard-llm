{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1866fecc-4c95-4421-97ee-3c5a4dadbfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5402e03-42f9-4253-9c10-680fe32f7c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 5082 Valid: 565 Test: 997\n",
      "Hazard classes: 10\n",
      "Product classes: 22\n"
     ]
    }
   ],
   "source": [
    "TRAIN_CSV = \"incidents_train.csv\"\n",
    "VALID_CSV = \"incidents_valid.csv\"\n",
    "TEST_CSV  = \"incidents_test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV).fillna(\"\")\n",
    "valid_df = pd.read_csv(VALID_CSV).fillna(\"\")\n",
    "test_df  = pd.read_csv(TEST_CSV).fillna(\"\")\n",
    "\n",
    "haz_labels = sorted(train_df[\"hazard-category\"].astype(str).unique().tolist())\n",
    "prod_labels = sorted(train_df[\"product-category\"].astype(str).unique().tolist())\n",
    "\n",
    "HAZ_LABELS = haz_labels\n",
    "PROD_LABELS = prod_labels\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Valid:\", len(valid_df), \"Test:\", len(test_df))\n",
    "print(\"Hazard classes:\", len(HAZ_LABELS))\n",
    "print(\"Product classes:\", len(PROD_LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "face17e3-4478-4377-a029-021521cf4fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB docs: 277\n",
      "[HAZARD DEFINITION]\n",
      "Label: allergens\n",
      "Definition: Allergen contamination or undeclared allergens (e.g., peanuts, milk, gl\n"
     ]
    }
   ],
   "source": [
    "def build_kb_docs(train_df, haz_labels, prod_labels, n_ex_per_label=8):\n",
    "    docs = []\n",
    "\n",
    "    # --- Hazard definitions ---\n",
    "    haz_def_map = {\n",
    "        \"allergens\": \"Allergen contamination or undeclared allergens (e.g., peanuts, milk, gluten).\",\n",
    "        \"biological\": \"Microbiological hazards: bacteria, viruses, parasites (e.g., Salmonella, Listeria).\",\n",
    "        \"chemical\": \"Chemical contamination (e.g., pesticides, cleaning agents, toxins, heavy metals).\",\n",
    "        \"food additives and flavourings\": \"Issues related to additives, colorants, preservatives, or flavorings.\",\n",
    "        \"foreign bodies\": \"Physical foreign objects in food (e.g., plastic, metal, glass, rubber).\",\n",
    "        \"fraud\": \"Mislabeling, adulteration, counterfeit, incorrect date/label claims, or regulatory deception.\",\n",
    "        \"migration\": \"Substances migrating from packaging/contact materials into food.\",\n",
    "        \"organoleptic aspects\": \"Sensory/quality issues (taste, odor, texture) affecting acceptability.\",\n",
    "        \"other hazard\": \"Hazard not covered by other categories.\",\n",
    "        \"packaging defect\": \"Packaging integrity issues (broken seals, leaks, bursting bottles, damaged packaging).\",\n",
    "    }\n",
    "\n",
    "    for lab in haz_labels:\n",
    "        definition = haz_def_map.get(lab, f\"Definition for hazard category '{lab}'.\")\n",
    "        docs.append({\n",
    "            \"id\": f\"haz_def::{lab}\",\n",
    "            \"kind\": \"haz_def\",\n",
    "            \"label\": lab,\n",
    "            \"text\": f\"[HAZARD DEFINITION]\\nLabel: {lab}\\nDefinition: {definition}\"\n",
    "        })\n",
    "\n",
    "    # --- Product definitions (lightweight) ---\n",
    "    for lab in prod_labels:\n",
    "        docs.append({\n",
    "            \"id\": f\"prod_def::{lab}\",\n",
    "            \"kind\": \"prod_def\",\n",
    "            \"label\": lab,\n",
    "            \"text\": f\"[PRODUCT DEFINITION]\\nLabel: {lab}\\nDefinition: Product category '{lab}'.\"\n",
    "        })\n",
    "\n",
    "    # --- Examples from train (targeted) ---\n",
    "    def add_examples(label_col, prefix, kind, labels):\n",
    "        for lab in labels:\n",
    "            sub = train_df[train_df[label_col].astype(str) == lab].head(n_ex_per_label)\n",
    "            for j, row in enumerate(sub.itertuples(index=False), start=0):\n",
    "                title = str(getattr(row, \"title\"))\n",
    "                text  = str(getattr(row, \"text\"))\n",
    "                docs.append({\n",
    "                    \"id\": f\"{prefix}::{lab}::{j}\",\n",
    "                    \"kind\": kind,\n",
    "                    \"label\": lab,\n",
    "                    \"text\": f\"[{kind.upper().replace('_',' ')}]\\nLabel: {lab}\\nTitle: {title}\\nText: {text}\"\n",
    "                })\n",
    "\n",
    "    add_examples(\"hazard-category\", \"haz_ex\", \"haz_ex\", haz_labels)\n",
    "    add_examples(\"product-category\", \"prod_ex\", \"prod_ex\", prod_labels)\n",
    "\n",
    "    return docs\n",
    "\n",
    "kb_docs = build_kb_docs(train_df, HAZ_LABELS, PROD_LABELS, n_ex_per_label=8)\n",
    "print(\"KB docs:\", len(kb_docs))\n",
    "print(kb_docs[0][\"text\"][:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5a2007-3c9e-41f9-a9ba-00bbd9c3605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1112dc377f704ada90c2d457b0db71e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haz def docs: 10 | Haz index: 10\n",
      "Prod docs: 192 | Prod index: 192\n"
     ]
    }
   ],
   "source": [
    "EMB_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformer(EMB_MODEL)\n",
    "\n",
    "def embed_texts(texts, batch_size=32, show_bar=False):\n",
    "    vecs = embedder.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=show_bar,  \n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    return vecs.astype(\"float32\")\n",
    "\n",
    "def build_faiss_index(docs):\n",
    "    texts = [d[\"text\"] for d in docs]\n",
    "    X = embed_texts(texts)\n",
    "    index = faiss.IndexFlatIP(X.shape[1])   # cosine sim via normalized vectors\n",
    "    index.add(X)\n",
    "    return index, X\n",
    "\n",
    "# --- Hybrid split ---\n",
    "haz_def_docs = [d for d in kb_docs if d[\"kind\"] == \"haz_def\"]      # ✅ فقط definitions\n",
    "prod_docs    = [d for d in kb_docs if d[\"kind\"] in (\"prod_def\",\"prod_ex\")]  # ✅ definitions + examples\n",
    "\n",
    "haz_index, _ = build_faiss_index(haz_def_docs)\n",
    "prod_index, _ = build_faiss_index(prod_docs)\n",
    "\n",
    "print(\"Haz def docs:\", len(haz_def_docs), \"| Haz index:\", haz_index.ntotal)\n",
    "print(\"Prod docs:\", len(prod_docs), \"| Prod index:\", prod_index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01814055-73fa-490f-907b-c960ad0e7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(index, docs, query_text, top_k=5):\n",
    "    q = embed_texts([query_text], batch_size=1, show_bar=False) \n",
    "    scores, idxs = index.search(q, top_k)\n",
    "    out = []\n",
    "    for s, i in zip(scores[0].tolist(), idxs[0].tolist()):\n",
    "        if i < 0:\n",
    "            continue\n",
    "        out.append((s, docs[i]))\n",
    "    return out\n",
    "\n",
    "def format_ctx(items, max_chars=1600):\n",
    "    blocks = []\n",
    "    total = 0\n",
    "    for score, d in items:\n",
    "        block = f\"(score={score:.3f}) {d['id']} | label={d['label']}\\n{d['text']}\"\n",
    "        if total + len(block) > max_chars:\n",
    "            break\n",
    "        blocks.append(block)\n",
    "        total += len(block)\n",
    "    return \"\\n\\n\".join(blocks)\n",
    "\n",
    "def get_rag_context_hybrid(title, text, k_h=1, k_p=5):\n",
    "    q = f\"{title}\\n{text}\"\n",
    "    haz_hits = retrieve(haz_index, haz_def_docs, q, top_k=k_h)   # ✅ hazard defs only\n",
    "    prod_hits = retrieve(prod_index, prod_docs, q, top_k=k_p)    # ✅ product full\n",
    "    return format_ctx(haz_hits), format_ctx(prod_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b720ee-3165-42c6-a27f-b01746ed2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT = \"\"\"\n",
    "You must output EXACTLY one line of valid JSON and NOTHING else.\n",
    "No explanations. No markdown. No extra text.\n",
    "\n",
    "Allowed hazard-category labels (copy EXACTLY one):\n",
    "{haz_list}\n",
    "\n",
    "Allowed product-category labels (copy EXACTLY one):\n",
    "{prod_list}\n",
    "\n",
    "[HAZARD KNOWLEDGE]\n",
    "{ctx_h}\n",
    "\n",
    "[PRODUCT KNOWLEDGE]\n",
    "{ctx_p}\n",
    "\n",
    "[RECALL REPORT]\n",
    "Title: {title}\n",
    "Text: {text}\n",
    "\n",
    "Return exactly:\n",
    "{{\"hazard-category\":\"<one hazard label>\",\"product-category\":\"<one product label>\"}}\n",
    "\"\"\".strip()\n",
    "\n",
    "def parse_json_one_line(s: str):\n",
    "    m = re.search(r\"\\{.*\\}\", s, flags=re.S)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(m.group(0))\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6befe02e-1630-4578-bb7c-843d928d7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"hazard-category\":\"biological\",\"product-category\":\"meat, egg and dairy products\"}\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "\n",
    "def llm_generate(prompt: str) -> str:\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You output JSON only. Never output explanations.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0,\n",
    "            \"num_predict\": 120\n",
    "        }\n",
    "    }\n",
    "    r = requests.post(url, json=payload, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"message\"][\"content\"]\n",
    "\n",
    "# quick sanity test\n",
    "print(llm_generate('Return ONLY this JSON in one line: {\"hazard-category\":\"biological\",\"product-category\":\"meat, egg and dairy products\"}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9745f7d-c280-429c-af1f-e7792761e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def run_hybrid_rag(df, k_h=1, k_p=5, max_rows=None):\n",
    "    y_h_true, y_h_pred = [], []\n",
    "    y_p_true, y_p_pred = [], []\n",
    "    parse_ok = 0\n",
    "    total = 0\n",
    "\n",
    "    rows = df if max_rows is None else df.head(max_rows)\n",
    "\n",
    "    for _, r in tqdm(rows.iterrows(), total=len(rows), desc=\"Hybrid RAG\", leave=True):\n",
    "        title = str(r[\"title\"])\n",
    "        text  = str(r[\"text\"])\n",
    "\n",
    "        ctx_h, ctx_p = get_rag_context_hybrid(title, text, k_h=k_h, k_p=k_p)\n",
    "\n",
    "        prompt = RAG_PROMPT.format(\n",
    "            haz_list=HAZ_LABELS,\n",
    "            prod_list=PROD_LABELS,\n",
    "            ctx_h=ctx_h,\n",
    "            ctx_p=ctx_p,\n",
    "            title=title,\n",
    "            text=text\n",
    "        )\n",
    "\n",
    "        out = llm_generate(prompt)\n",
    "        obj = parse_json_one_line(out)\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        if obj and \"hazard-category\" in obj and \"product-category\" in obj:\n",
    "            hz = obj[\"hazard-category\"]\n",
    "            pr = obj[\"product-category\"]\n",
    "\n",
    "            if hz in HAZ_LABELS and pr in PROD_LABELS:\n",
    "                parse_ok += 1\n",
    "                y_h_true.append(r[\"hazard-category\"])\n",
    "                y_h_pred.append(hz)\n",
    "                y_p_true.append(r[\"product-category\"])\n",
    "                y_p_pred.append(pr)\n",
    "\n",
    "    def metrics(y_true, y_pred):\n",
    "        if len(y_true) == 0:\n",
    "            return {\"acc\":0,\"macro_f1\":0,\"micro_f1\":0,\"weighted_f1\":0}\n",
    "        return {\n",
    "            \"acc\": accuracy_score(y_true, y_pred),\n",
    "            \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "            \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
    "            \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"parse_ok_rate\": parse_ok / max(total,1),\n",
    "        \"n_total\": total,\n",
    "        \"n_parse_ok\": parse_ok,\n",
    "        \"hazard\": metrics(y_h_true, y_h_pred),\n",
    "        \"product\": metrics(y_p_true, y_p_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "395fbd99-0251-45d3-8bad-75ce9d8d9ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bde56235b247ff8acfdf2877bbe111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hybrid RAG:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOKE: {'parse_ok_rate': 1.0, 'n_total': 30, 'n_parse_ok': 30, 'hazard': {'acc': 0.3333333333333333, 'macro_f1': 0.23820297349709116, 'micro_f1': 0.3333333333333333, 'weighted_f1': 0.3352187028657617}, 'product': {'acc': 0.5333333333333333, 'macro_f1': 0.42600732600732594, 'micro_f1': 0.5333333333333333, 'weighted_f1': 0.5326984126984127}}\n"
     ]
    }
   ],
   "source": [
    "# smoke\n",
    "smoke = run_hybrid_rag(valid_df, k_h=1, k_p=5, max_rows=30)\n",
    "print(\"SMOKE:\", smoke)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39fbe7ea-87f8-4fec-a884-cd22a6b90db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ee6d5927b643f4b51baaa0617a9c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hybrid RAG:   0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID HYBRID: {'parse_ok_rate': 0.9964601769911504, 'n_total': 565, 'n_parse_ok': 563, 'hazard': {'acc': 0.36767317939609234, 'macro_f1': 0.1852865297189791, 'micro_f1': 0.36767317939609234, 'weighted_f1': 0.40747091540909086}, 'product': {'acc': 0.41207815275310833, 'macro_f1': 0.37913966695272266, 'micro_f1': 0.41207815275310833, 'weighted_f1': 0.42425313104242834}}\n"
     ]
    }
   ],
   "source": [
    "# full valid\n",
    "res_valid_hybrid = run_hybrid_rag(valid_df, k_h=1, k_p=5)\n",
    "print(\"VALID HYBRID:\", res_valid_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6cefa-2257-4586-9971-1b1c9a50ca9a",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1e8ac2-e970-49db-a800-6d3578cb33b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed09bceb4ba4009a1977b1ab57031d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hybrid RAG:   0%|          | 0/997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST HYBRID (k_h=1, k_p=5): {'parse_ok_rate': 0.9899699097291875, 'n_total': 997, 'n_parse_ok': 987, 'hazard': {'acc': 0.3617021276595745, 'macro_f1': 0.1779860956140859, 'micro_f1': 0.3617021276595745, 'weighted_f1': 0.39705575042621366}, 'product': {'acc': 0.44782168186423504, 'macro_f1': 0.38151108644541865, 'micro_f1': 0.44782168186423504, 'weighted_f1': 0.4597753456295018}}\n"
     ]
    }
   ],
   "source": [
    "res_test_hybrid = run_hybrid_rag(test_df, k_h=1, k_p=5)\n",
    "print(\"TEST HYBRID (k_h=1, k_p=5):\", res_test_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120f282-7096-477d-b021-a2d3ccc6f024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
