{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459d2c35-d692-4f01-9d28-a9b9e00f0f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB docs: 277\n",
      "[HAZARD DEFINITION]\n",
      "Label: allergens\n",
      "Definition: Allergen contamination or undeclared allergens (e.g., peanuts, milk, gluten).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "TRAIN_CSV = \"incidents_train.csv\"\n",
    "train_df = pd.read_csv(TRAIN_CSV).fillna(\"\")\n",
    "\n",
    "# label lists\n",
    "haz_labels = sorted(train_df[\"hazard-category\"].unique().tolist())\n",
    "prod_labels = sorted(train_df[\"product-category\"].unique().tolist())\n",
    "\n",
    "def short_text(s, n=350):\n",
    "    s = str(s).replace(\"\\n\", \" \").strip()\n",
    "    return s[:n]\n",
    "\n",
    "\n",
    "HAZ_DEF = {\n",
    "    \"allergens\": \"Allergen contamination or undeclared allergens (e.g., peanuts, milk, gluten).\",\n",
    "    \"biological\": \"Microbiological hazards: bacteria, viruses, parasites (e.g., Salmonella, Listeria).\",\n",
    "    \"chemical\": \"Chemical contamination: toxins, residues, cleaning agents, heavy metals.\",\n",
    "    \"food additives and flavourings\": \"Issues with additives/flavourings: unauthorized, excessive, misused.\",\n",
    "    \"foreign bodies\": \"Physical foreign objects in food: plastic, metal, glass, stones.\",\n",
    "    \"fraud\": \"Food fraud/mislabelling/adulteration: substitution, counterfeit, incorrect origin.\",\n",
    "    \"migration\": \"Migration of substances from packaging/contact materials into food.\",\n",
    "    \"organoleptic aspects\": \"Quality/sensory issues: taste, smell, texture, spoilage not necessarily pathogens.\",\n",
    "    \"other hazard\": \"Hazard type not covered by other categories (miscellaneous).\",\n",
    "    \"packaging defect\": \"Defects in packaging integrity: seal failure, leakage, broken packaging.\"\n",
    "}\n",
    "\n",
    "PROD_DEF = {lab: f\"Product category: {lab}.\" for lab in prod_labels}  \n",
    "\n",
    "# --- Build documents\n",
    "docs = []\n",
    "\n",
    "# Hazard definition docs\n",
    "for lab in haz_labels:\n",
    "    definition = HAZ_DEF.get(lab, f\"Hazard category: {lab}.\")\n",
    "    docs.append({\n",
    "        \"doc_id\": f\"haz_def::{lab}\",\n",
    "        \"group\": \"hazard\",\n",
    "        \"label\": lab,\n",
    "        \"text\": f\"[HAZARD DEFINITION]\\nLabel: {lab}\\nDefinition: {definition}\"\n",
    "    })\n",
    "\n",
    "# Product definition docs\n",
    "for lab in prod_labels:\n",
    "    definition = PROD_DEF.get(lab, f\"Product category: {lab}.\")\n",
    "    docs.append({\n",
    "        \"doc_id\": f\"prod_def::{lab}\",\n",
    "        \"group\": \"product\",\n",
    "        \"label\": lab,\n",
    "        \"text\": f\"[PRODUCT DEFINITION]\\nLabel: {lab}\\nDefinition: {definition}\"\n",
    "    })\n",
    "\n",
    "# --- Example docs (few per label from TRAIN only)\n",
    "EXAMPLES_PER_LABEL = 8 \n",
    "def sample_examples(df, col, label, k):\n",
    "    sub = df[df[col] == label]\n",
    "    if len(sub) == 0:\n",
    "        return []\n",
    "    idxs = list(sub.index)\n",
    "    random.shuffle(idxs)\n",
    "    idxs = idxs[:min(k, len(idxs))]\n",
    "    rows = []\n",
    "    for i in idxs:\n",
    "        r = df.loc[i]\n",
    "        rows.append(\n",
    "            f\"Title: {short_text(r['title'],120)}\\nText: {short_text(r['text'],350)}\\n\"\n",
    "        )\n",
    "    return rows\n",
    "\n",
    "for lab in haz_labels:\n",
    "    exs = sample_examples(train_df, \"hazard-category\", lab, EXAMPLES_PER_LABEL)\n",
    "    for j, ex in enumerate(exs):\n",
    "        docs.append({\n",
    "            \"doc_id\": f\"haz_ex::{lab}::{j}\",\n",
    "            \"group\": \"hazard\",\n",
    "            \"label\": lab,\n",
    "            \"text\": f\"[HAZARD EXAMPLE]\\nLabel: {lab}\\n{ex}\"\n",
    "        })\n",
    "\n",
    "for lab in prod_labels:\n",
    "    exs = sample_examples(train_df, \"product-category\", lab, EXAMPLES_PER_LABEL)\n",
    "    for j, ex in enumerate(exs):\n",
    "        docs.append({\n",
    "            \"doc_id\": f\"prod_ex::{lab}::{j}\",\n",
    "            \"group\": \"product\",\n",
    "            \"label\": lab,\n",
    "            \"text\": f\"[PRODUCT EXAMPLE]\\nLabel: {lab}\\n{ex}\"\n",
    "        })\n",
    "\n",
    "print(\"KB docs:\", len(docs))\n",
    "print(docs[0][\"text\"][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023720e8-1f25-4409-8d21-937f99d969e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732e6372cb1b4c1e99a3ab3bc456b3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37de39e006347a48da37871752d587c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (277, 384)\n",
      "FAISS index size: 277\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMB_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformer(EMB_MODEL)\n",
    "\n",
    "corpus_texts = [d[\"text\"] for d in docs]\n",
    "\n",
    "emb = embedder.encode(\n",
    "    corpus_texts,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# cosine similarity via normalized inner product\n",
    "faiss.normalize_L2(emb)\n",
    "dim = emb.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(emb)\n",
    "\n",
    "print(\"Embedding shape:\", emb.shape)\n",
    "print(\"FAISS index size:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e52004-87ac-4695-8ca6-44aeb92a702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- HAZARD TOP-5 ---\n",
      "\n",
      "score=0.624 | haz_ex::biological::5 | label=biological\n",
      "[HAZARD EXAMPLE]\n",
      "Label: biological\n",
      "Title: Recall of Additional Smoked Meat Products sold at Finns Butchers’ Shop, Co. Cork Due to Processing in an Unapproved Faci\n",
      "Text: Recall of Additional Smoked Meat Products sold at F\n",
      "\n",
      "score=0.621 | haz_ex::foreign bodies::5 | label=foreign bodies\n",
      "[HAZARD EXAMPLE]\n",
      "Label: foreign bodies\n",
      "Title: Schneiders brand Mock Chicken Loaf recalled due to presence of pieces of rubber\n",
      "Text: Notice This archive of previously issued food recalls and allergy alerts is provided for\n",
      "\n",
      "score=0.613 | haz_ex::packaging defect::6 | label=packaging defect\n",
      "[HAZARD EXAMPLE]\n",
      "Label: packaging defect\n",
      "Title: President's Choice brand Roasted Garlic Mayo Sandwich Spread recalled due to bursting bottles\n",
      "Text: Notification - President's Choice brand Roasted Garlic Mayo Sandwich Spr\n",
      "\n",
      "score=0.604 | haz_ex::biological::2 | label=biological\n",
      "[HAZARD EXAMPLE]\n",
      "Label: biological\n",
      "Title: Pepperidge Farm brand Goldfish Flavour Blasted Xtreme Cheddar Crackers recalled due to Salmonella\n",
      "Text: Food Recall Warning - Pepperidge Farm brand Goldfish Flavour Blasted Xtrem\n",
      "\n",
      "score=0.599 | haz_ex::biological::3 | label=biological\n",
      "[HAZARD EXAMPLE]\n",
      "Label: biological\n",
      "Title: Listeria monocytogenes in cheese by Cahill’s from Ireland\n",
      "Text: Recall of Several Cahills Farm Cheese Products due to the Possible Presence of Listeria monocytogenes Friday, 23 J\n",
      "\n",
      "--- PRODUCT TOP-5 ---\n",
      "\n",
      "score=0.675 | prod_ex::prepared dishes and snacks::7 | label=prepared dishes and snacks\n",
      "[PRODUCT EXAMPLE]\n",
      "Label: prepared dishes and snacks\n",
      "Title: Culinary Creations Gourmet brand & Denny's Express brand roast beef-containing sandwiches recalled due to Listeria monoc\n",
      "Text: Updated Food Recall Warning - Culi\n",
      "\n",
      "score=0.665 | prod_ex::meat, egg and dairy products::3 | label=meat, egg and dairy products\n",
      "[PRODUCT EXAMPLE]\n",
      "Label: meat, egg and dairy products\n",
      "Title: Recall Notification: FSIS-023-96\n",
      "Text: Case Number: 023-96  Recall Notification Report:  N                  Date Opened: 11/12/1996                Date Closed:\n",
      "\n",
      "score=0.650 | prod_ex::meat, egg and dairy products::6 | label=meat, egg and dairy products\n",
      "[PRODUCT EXAMPLE]\n",
      "Label: meat, egg and dairy products\n",
      "Title: Recall Notification: FSIS-024-94\n",
      "Text: Case Number: 024-94                Date Opened: 07/01/1994                Date Closed: 09/22/1994                   Reca\n",
      "\n",
      "score=0.642 | prod_ex::soups, broths, sauces and condiments::1 | label=soups, broths, sauces and condiments\n",
      "[PRODUCT EXAMPLE]\n",
      "Label: soups, broths, sauces and condiments\n",
      "Title: Chef Destinations, Frankly Fresh Salads and Fresh St. brands Fresh Guacamole and 7 Layer Dip recalled due to Listeria mo\n",
      "Text: Updated Food Recall Warn\n",
      "\n",
      "score=0.628 | prod_ex::fruits and vegetables::0 | label=fruits and vegetables\n",
      "[PRODUCT EXAMPLE]\n",
      "Label: fruits and vegetables\n",
      "Title: Picoudi brand microgreens recalled due to Salmonella\n",
      "Text: Food Recall Warning - Picoudi brand microgreens recalled due to Salmonella From: Canadian Food Inspection A\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "def retrieve(query, k=5, group=None):\n",
    "    q_emb = embedder.encode([query], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    scores, ids = index.search(q_emb, k*6)  \n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(scores[0], ids[0]):\n",
    "        d = docs[int(idx)]\n",
    "        if group is None or d[\"group\"] == group:\n",
    "            results.append((float(score), d))\n",
    "        if len(results) >= k:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "\n",
    "sample_query = \"\"\"Recall Notification: FSIS-024-94\n",
    "Product: SMOKED CHICKEN SAUSAGE\n",
    "Problem: BACTERIA\n",
    "Description: LISTERIA\"\"\"\n",
    "\n",
    "haz_hits = retrieve(sample_query, k=5, group=\"hazard\")\n",
    "prod_hits = retrieve(sample_query, k=5, group=\"product\")\n",
    "\n",
    "print(\"\\n--- HAZARD TOP-5 ---\")\n",
    "for s, d in haz_hits:\n",
    "    print(f\"\\nscore={s:.3f} | {d['doc_id']} | label={d['label']}\")\n",
    "    print(d[\"text\"][:220])\n",
    "\n",
    "print(\"\\n--- PRODUCT TOP-5 ---\")\n",
    "for s, d in prod_hits:\n",
    "    print(f\"\\nscore={s:.3f} | {d['doc_id']} | label={d['label']}\")\n",
    "    print(d[\"text\"][:220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7a50fd-c4e1-4cd2-89c8-914946cbbc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae135ad64d24dd9ac5654773c24da9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38195abd77284a828768c9ac74160c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haz docs: 85  | Haz index: 85\n",
      "Prod docs: 192  | Prod index: 192\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# --- split docs\n",
    "haz_docs = [d for d in docs if d[\"group\"] == \"hazard\"]\n",
    "prod_docs = [d for d in docs if d[\"group\"] == \"product\"]\n",
    "\n",
    "# --- embed separately\n",
    "haz_texts = [d[\"text\"] for d in haz_docs]\n",
    "prod_texts = [d[\"text\"] for d in prod_docs]\n",
    "\n",
    "haz_emb = embedder.encode(haz_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "prod_emb = embedder.encode(prod_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "faiss.normalize_L2(haz_emb)\n",
    "faiss.normalize_L2(prod_emb)\n",
    "\n",
    "haz_index = faiss.IndexFlatIP(haz_emb.shape[1])\n",
    "prod_index = faiss.IndexFlatIP(prod_emb.shape[1])\n",
    "\n",
    "haz_index.add(haz_emb)\n",
    "prod_index.add(prod_emb)\n",
    "\n",
    "print(\"Haz docs:\", len(haz_docs), \" | Haz index:\", haz_index.ntotal)\n",
    "print(\"Prod docs:\", len(prod_docs), \" | Prod index:\", prod_index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf958d6-105f-4549-a6f9-1f0eab3880f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_def(query, index, docs_list, k=5):\n",
    "    q_emb = embedder.encode([query], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    scores, ids = index.search(q_emb, k*8)\n",
    "\n",
    "\n",
    "    defs = []\n",
    "    exs = []\n",
    "    for s, idx in zip(scores[0], ids[0]):\n",
    "        d = docs_list[int(idx)]\n",
    "        if \"::def::\" in d[\"doc_id\"] or d[\"doc_id\"].startswith((\"haz_def::\", \"prod_def::\")):\n",
    "            defs.append((float(s), d))\n",
    "        else:\n",
    "            exs.append((float(s), d))\n",
    "\n",
    "\n",
    "    chosen = []\n",
    "    if len(defs) > 0:\n",
    "        chosen.append(defs[0]) \n",
    "    chosen.extend(exs[:max(0, k - len(chosen))])\n",
    "    return chosen\n",
    "\n",
    "def get_rag_context(title, text, k_h=5, k_p=5):\n",
    "    query = (str(title) + \" \" + str(text)).strip()\n",
    "    haz_hits = retrieve_with_def(query, haz_index, haz_docs, k=k_h)\n",
    "    prod_hits = retrieve_with_def(query, prod_index, prod_docs, k=k_p)\n",
    "\n",
    "    ctx_h = \"\\n\\n\".join([f\"(score={s:.3f}) {d['doc_id']} | label={d['label']}\\n{d['text']}\" for s,d in haz_hits])\n",
    "    ctx_p = \"\\n\\n\".join([f\"(score={s:.3f}) {d['doc_id']} | label={d['label']}\\n{d['text']}\" for s,d in prod_hits])\n",
    "    return ctx_h, ctx_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11e4241-b3b8-420a-89bb-9c9f5b0be916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- HAZARD CONTEXT (preview) ---\n",
      " (score=0.417) haz_def::biological | label=biological\n",
      "[HAZARD DEFINITION]\n",
      "Label: biological\n",
      "Definition: Microbiological hazards: bacteria, viruses, parasites (e.g., Salmonella, Listeria).\n",
      "\n",
      "(score=0.624) haz_ex::biological::5 | label=biological\n",
      "[HAZARD EXAMPLE]\n",
      "Label: biological\n",
      "Title: Recall of Additional Smoked Meat Products sold at Finns Butchers’ Shop, Co. Cork Due to Processing in an Unapproved Faci\n",
      "Text: Recall of Additional Smoked Meat Products sold at Finns Butchers’ Shop, Co. Cork Due to Processing in an Unapproved Facility Tweet Thursday, 16 August 2018 Summary Category 2: For Informat\n",
      "\n",
      "--- PRODUCT CONTEXT (preview) ---\n",
      " (score=0.675) prod_ex::prepared dishes and snacks::7 | label=prepared dishes and snacks\n",
      "[PRODUCT EXAMPLE]\n",
      "Label: prepared dishes and snacks\n",
      "Title: Culinary Creations Gourmet brand & Denny's Express brand roast beef-containing sandwiches recalled due to Listeria monoc\n",
      "Text: Updated Food Recall Warning - Culinary Creations Gourmet brand & Denny's Express brand roast beef-containing sandwiches recalled due to Listeria monocytogenes Recall date: April 18, 2018 Reason for recall: Microbiological - Listeria Hazard classification: Class 1 Company / Firm: R.T. Fresh Prepared Foods Inc. Distribution: A\n"
     ]
    }
   ],
   "source": [
    "sample_title = \"Recall Notification: FSIS-024-94\"\n",
    "sample_text = \"\"\"Product: SMOKED CHICKEN SAUSAGE\n",
    "Problem: BACTERIA\n",
    "Description: LISTERIA\"\"\"\n",
    "\n",
    "ctx_h, ctx_p = get_rag_context(sample_title, sample_text, k_h=5, k_p=5)\n",
    "print(\"\\n--- HAZARD CONTEXT (preview) ---\\n\", ctx_h[:600])\n",
    "print(\"\\n--- PRODUCT CONTEXT (preview) ---\\n\", ctx_p[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3658d692-8b51-4976-b14a-bc8a74e43abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition: Product category 'meat, egg and dairy products'.\n",
      "Typical keywords/items: products, food, consumers, milk, fsis, beef, should, recalled, allergy, sold, available, usda, chicken, safety.\n",
      "Typical recall titles: Thai Chicken Panang withdrawn (update) | Lion-Dairy & Drinks Pty Ltd—Masters Flavoured Milk | Mrs. Grissom’s Salads Issues a Voluntary Recall | Müller Kids Corner Butterflies Strawberry Yogurt recalled as a single pot from t | CFS urges public not to consume a kind of Italian sausage suspected to be contam\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def extract_keywords(text, topn=12):\n",
    "\n",
    "    toks = re.findall(r\"[a-zA-Z]{4,}\", str(text).lower())\n",
    "    stop = set([\"this\",\"that\",\"with\",\"from\",\"have\",\"were\",\"will\",\"been\",\"case\",\"date\",\"closed\",\"opened\",\n",
    "                \"recall\",\"notification\",\"report\",\"press\",\"release\",\"product\",\"problem\",\"description\",\n",
    "                \"company\",\"class\",\"total\",\"pounds\",\"recovered\",\"distribution\",\"reason\",\"risk\",\"possible\"])\n",
    "    toks = [t for t in toks if t not in stop]\n",
    "    return [w for w,_ in Counter(toks).most_common(topn)]\n",
    "\n",
    "\n",
    "PROD_DEF_RICH = {}\n",
    "SAMPLE_PER_PROD_DEF = 30  \n",
    "\n",
    "for lab in prod_labels:\n",
    "    sub = train_df[train_df[\"product-category\"] == lab]\n",
    "    if len(sub) == 0:\n",
    "        PROD_DEF_RICH[lab] = f\"Product category: {lab}.\"\n",
    "        continue\n",
    "\n",
    "    # sample rows\n",
    "    rows = sub.sample(n=min(SAMPLE_PER_PROD_DEF, len(sub)), random_state=SEED)\n",
    "    joined = \" \".join((rows[\"title\"].astype(str) + \" \" + rows[\"text\"].astype(str)).tolist())\n",
    "\n",
    "    kw = extract_keywords(joined, topn=14)\n",
    "\n",
    "\n",
    "    ex_titles = rows[\"title\"].astype(str).tolist()[:5]\n",
    "    ex_titles = [short_text(t, 80) for t in ex_titles]\n",
    "\n",
    "    PROD_DEF_RICH[lab] = (\n",
    "        f\"Definition: Product category '{lab}'.\\n\"\n",
    "        f\"Typical keywords/items: {', '.join(kw)}.\\n\"\n",
    "        f\"Typical recall titles: \" + \" | \".join(ex_titles)\n",
    "    )\n",
    "\n",
    "\n",
    "print(PROD_DEF_RICH[\"meat, egg and dairy products\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d48f9c-2e97-4d79-9803-ff11beb70c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4226638a4c0d4dcf8bcc2352788dddd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prod docs: 192 | Prod index: 192\n"
     ]
    }
   ],
   "source": [
    "# 1) update product definition docs in-place\n",
    "for d in docs:\n",
    "    if d[\"doc_id\"].startswith(\"prod_def::\"):\n",
    "        lab = d[\"label\"]\n",
    "        d[\"text\"] = f\"[PRODUCT DEFINITION]\\nLabel: {lab}\\n{PROD_DEF_RICH.get(lab, f'Product category: {lab}.')}\"\n",
    "\n",
    "# 2) rebuild prod_docs, embeddings, index\n",
    "prod_docs = [d for d in docs if d[\"group\"] == \"product\"]\n",
    "prod_texts = [d[\"text\"] for d in prod_docs]\n",
    "\n",
    "prod_emb = embedder.encode(prod_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "faiss.normalize_L2(prod_emb)\n",
    "\n",
    "prod_index = faiss.IndexFlatIP(prod_emb.shape[1])\n",
    "prod_index.add(prod_emb)\n",
    "\n",
    "print(\"Prod docs:\", len(prod_docs), \"| Prod index:\", prod_index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b847a8d-5f2e-4072-8a1b-bd3bf5c7ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRODUCT CONTEXT (preview) ---\n",
      " (score=0.630) prod_def::meat, egg and dairy products | label=meat, egg and dairy products\n",
      "[PRODUCT DEFINITION]\n",
      "Label: meat, egg and dairy products\n",
      "Definition: Product category 'meat, egg and dairy products'.\n",
      "Typical keywords/items: products, food, consumers, milk, fsis, beef, should, recalled, allergy, sold, available, usda, chicken, safety.\n",
      "Typical recall titles: Thai Chicken Panang withdrawn (update) | Lion-Dairy & Drinks Pty Ltd—Masters Flavoured Milk | Mrs. Grissom’s Salads Issues a Voluntary Recall | Müller Kids Corner Butterflies Strawberry Yogurt recalled as a single pot from t | CFS ur\n"
     ]
    }
   ],
   "source": [
    "ctx_h, ctx_p = get_rag_context(sample_title, sample_text, k_h=5, k_p=5)\n",
    "print(\"\\n--- PRODUCT CONTEXT (preview) ---\\n\", ctx_p[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34035c7-dec2-41bf-b3a6-0bd896743a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "HAZ_LABELS = haz_labels\n",
    "PROD_LABELS = prod_labels\n",
    "\n",
    "RAG_PROMPT = \"\"\"\n",
    "You must output EXACTLY one line of valid JSON and NOTHING else.\n",
    "No explanations. No markdown. No extra text.\n",
    "\n",
    "Allowed hazard-category labels (copy EXACTLY one):\n",
    "{haz_list}\n",
    "\n",
    "Allowed product-category labels (copy EXACTLY one):\n",
    "{prod_list}\n",
    "\n",
    "[HAZARD KNOWLEDGE]\n",
    "{ctx_h}\n",
    "\n",
    "[PRODUCT KNOWLEDGE]\n",
    "{ctx_p}\n",
    "\n",
    "[RECALL REPORT]\n",
    "Title: {title}\n",
    "Text: {text}\n",
    "\n",
    "Return exactly this JSON schema:\n",
    "{{\"hazard-category\":\"<one label from allowed hazard list>\",\"product-category\":\"<one label from allowed product list>\"}}\n",
    "\"\"\".strip()\n",
    "def parse_json_one_line(s: str):\n",
    "    m = re.search(r\"\\{.*\\}\", s, flags=re.S)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        obj = json.loads(m.group(0))\n",
    "        return obj\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3d9fad-8f30-4f96-964b-a06878f61e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "\n",
    "def llm_generate(prompt: str) -> str:\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You output JSON only. Never output explanations.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0,\n",
    "            \"num_predict\": 120\n",
    "        }\n",
    "    }\n",
    "    r = requests.post(url, json=payload, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83acf2c6-f478-4cb3-a497-9cfe48c2fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"hazard-category\":\"biological\",\"product-category\":\"meat, egg and dairy products\"}\n"
     ]
    }
   ],
   "source": [
    "print(llm_generate('Return ONLY this JSON in one line: {\"hazard-category\":\"biological\",\"product-category\":\"meat, egg and dairy products\"}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48493162-4ccd-4054-97d1-8b8e8de7d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def run_rag(df, k_h=3, k_p=3, max_rows=None):\n",
    "    y_h_true, y_h_pred = [], []\n",
    "    y_p_true, y_p_pred = [], []\n",
    "    parse_ok = 0\n",
    "    total = 0\n",
    "\n",
    "    rows = df if max_rows is None else df.head(max_rows)\n",
    "\n",
    "    for _, r in tqdm(rows.iterrows(), total=len(rows)):\n",
    "        title = str(r[\"title\"])\n",
    "        text  = str(r[\"text\"])\n",
    "\n",
    "        ctx_h, ctx_p = get_rag_context(title, text, k_h=k_h, k_p=k_p)\n",
    "\n",
    "        prompt = RAG_PROMPT.format(\n",
    "            haz_list=HAZ_LABELS,\n",
    "            prod_list=PROD_LABELS,\n",
    "            ctx_h=ctx_h,\n",
    "            ctx_p=ctx_p,\n",
    "            title=title,\n",
    "            text=text\n",
    "        )\n",
    "\n",
    "        out = llm_generate(prompt)\n",
    "        obj = parse_json_one_line(out)\n",
    "\n",
    "        total += 1\n",
    "        if obj and \"hazard-category\" in obj and \"product-category\" in obj:\n",
    "            hz = obj[\"hazard-category\"]\n",
    "            pr = obj[\"product-category\"]\n",
    "            if hz in HAZ_LABELS and pr in PROD_LABELS:\n",
    "                parse_ok += 1\n",
    "                y_h_true.append(r[\"hazard-category\"])\n",
    "                y_h_pred.append(hz)\n",
    "                y_p_true.append(r[\"product-category\"])\n",
    "                y_p_pred.append(pr)\n",
    "\n",
    "    def metrics(y_true, y_pred):\n",
    "        if len(y_true) == 0:\n",
    "            return {\"acc\":0,\"macro_f1\":0,\"micro_f1\":0,\"weighted_f1\":0}\n",
    "        return {\n",
    "            \"acc\": accuracy_score(y_true, y_pred),\n",
    "            \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "            \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
    "            \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"parse_ok_rate\": parse_ok / max(total,1),\n",
    "        \"n_total\": total,\n",
    "        \"n_parse_ok\": parse_ok,\n",
    "        \"hazard\": metrics(y_h_true, y_h_pred),\n",
    "        \"product\": metrics(y_p_true, y_p_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b2538-c08f-4173-99b4-cfac483853dd",
   "metadata": {},
   "source": [
    "## FIRST 30 ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67adb12e-6cde-4ca0-a4c7-8ee36597d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:32<00:00,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parse_ok_rate': 1.0, 'n_total': 30, 'n_parse_ok': 30, 'hazard': {'acc': 0.3, 'macro_f1': 0.20455840455840454, 'micro_f1': 0.3, 'weighted_f1': 0.34923076923076923}, 'product': {'acc': 0.5666666666666667, 'macro_f1': 0.5470085470085471, 'micro_f1': 0.5666666666666667, 'weighted_f1': 0.5933333333333333}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "valid_df = pd.read_csv(\"incidents_valid.csv\").fillna(\"\")\n",
    "\n",
    "res_smoke = run_rag(valid_df, k_h=3, k_p=3, max_rows=30)\n",
    "print(res_smoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc2439ed-81b7-4371-87bf-3b1d1042797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_debug(df, k_h=3, k_p=3, max_rows=30, show_fail=5):\n",
    "    parse_ok = 0\n",
    "    total = 0\n",
    "    shown = 0\n",
    "\n",
    "    rows = df.head(max_rows)\n",
    "\n",
    "    for i, r in rows.iterrows():\n",
    "        title = str(r[\"title\"])\n",
    "        text  = str(r[\"text\"])\n",
    "        ctx_h, ctx_p = get_rag_context(title, text, k_h=k_h, k_p=k_p)\n",
    "\n",
    "        prompt = RAG_PROMPT.format(\n",
    "            haz_list=HAZ_LABELS,\n",
    "            prod_list=PROD_LABELS,\n",
    "            ctx_h=ctx_h,\n",
    "            ctx_p=ctx_p,\n",
    "            title=title,\n",
    "            text=text\n",
    "        )\n",
    "\n",
    "        out = llm_generate(prompt)\n",
    "        obj = parse_json_one_line(out)\n",
    "\n",
    "        total += 1\n",
    "        ok = True\n",
    "        reason = \"\"\n",
    "\n",
    "        if not obj:\n",
    "            ok = False\n",
    "            reason = \"no_json_parsed\"\n",
    "        else:\n",
    "            hz = obj.get(\"hazard-category\", None)\n",
    "            pr = obj.get(\"product-category\", None)\n",
    "\n",
    "            if hz not in HAZ_LABELS:\n",
    "                ok = False\n",
    "                reason = f\"bad_hazard_label: {hz}\"\n",
    "            if pr not in PROD_LABELS:\n",
    "                ok = False\n",
    "                reason = f\"bad_product_label: {pr}\"\n",
    "\n",
    "        if ok:\n",
    "            parse_ok += 1\n",
    "        else:\n",
    "            if shown < show_fail:\n",
    "                print(\"\\n================ FAIL SAMPLE ================\")\n",
    "                print(\"Reason:\", reason)\n",
    "                print(\"GT hazard:\", r[\"hazard-category\"])\n",
    "                print(\"GT product:\", r[\"product-category\"])\n",
    "                print(\"\\nModel output:\\n\", out[:800])\n",
    "                shown += 1\n",
    "\n",
    "    print(\"\\nParse OK:\", parse_ok, \"/\", total, \"=\", parse_ok/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebd972eb-1b47-46d6-87af-79a8d9bcd085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ FAIL SAMPLE ================\n",
      "Reason: no_json_parsed\n",
      "GT hazard: biological\n",
      "GT product: meat, egg and dairy products\n",
      "\n",
      "Model output:\n",
      " Based on the provided recall report, I will make predictions for hazard-category and product-category.\n",
      "\n",
      "**Hazard-Category:** fraud\n",
      "The reason is that the title of the recall notification mentions \"misbranded\" products, which implies a fraudulent activity. The text also states that the products were produced without the benefit of federal inspection, further supporting this classification.\n",
      "\n",
      "**Product-Category:** meat, egg and dairy products\n",
      "This classification is based on the product name mentioned in the recall report: \"DRY SALAMI\". Dry salami is a type of cured meat product, which falls under the category of\n",
      "\n",
      "================ FAIL SAMPLE ================\n",
      "Reason: no_json_parsed\n",
      "GT hazard: allergens\n",
      "GT product: ices and desserts\n",
      "\n",
      "Model output:\n",
      " Based on the provided knowledge and constraints, I will make a prediction for the hazard-category and product-category.\n",
      "\n",
      "**Hazard-Category:** allergens\n",
      "**Product-Category:** ices and desserts\n",
      "\n",
      "Here's my reasoning:\n",
      "\n",
      "* The recall report mentions \"undeclared nuts\" in Originale Augustin brand French Vanilla Ice Cream, which is a clear indication of an allergen-related issue.\n",
      "* The typical keywords/items for the product category \"ices and desserts\" include products with cream, allergy, and milk, which aligns with the context of the recall report.\n",
      "\n",
      "Therefore, my prediction is:\n",
      "\n",
      "{\"\n",
      "\n",
      "================ FAIL SAMPLE ================\n",
      "Reason: no_json_parsed\n",
      "GT hazard: packaging defect\n",
      "GT product: alcoholic beverages\n",
      "\n",
      "Model output:\n",
      " Based on the retrieved knowledge, I will make a prediction.\n",
      "\n",
      "**Hazard-category:** packaging defect\n",
      "**Product-category:** alcoholic beverages\n",
      "\n",
      "Here's my reasoning:\n",
      "\n",
      "* The title of the recall report mentions \"shattering\" and \"bottles have shattered\", which suggests that there is an issue with the packaging.\n",
      "* The product category mentioned in the text is \"Drinks\", but based on the retrieved knowledge, I can see that \"alcoholic beverages\" is a more specific and relevant category.\n",
      "\n",
      "Here's my output:\n",
      "\n",
      "{\"hazard-category\": \"packaging defect\", \"product-category\": \"\n",
      "\n",
      "================ FAIL SAMPLE ================\n",
      "Reason: no_json_parsed\n",
      "GT hazard: biological\n",
      "GT product: seafood\n",
      "\n",
      "Model output:\n",
      " Based on the provided knowledge, I will make a prediction for the hazard-category and product-category.\n",
      "\n",
      "**Hazard-Category:** fraud\n",
      "**Product-Category:** seafood\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The text mentions \"Application of incorrect 'Use By' date (18DEC18)\" which suggests that the product is not safe to consume due to incorrect labeling, which falls under the category of \"fraud\".\n",
      "* The product description includes \"Sliced smoked salmon 100g\" which indicates that it is a type of seafood.\n",
      "\n",
      "Therefore, my prediction is:\n",
      "\n",
      "{\"hazard-category\": \"fraud\",\n",
      "\n",
      "================ FAIL SAMPLE ================\n",
      "Reason: no_json_parsed\n",
      "GT hazard: foreign bodies\n",
      "GT product: meat, egg and dairy products\n",
      "\n",
      "Model output:\n",
      " Based on the provided text, I will make a prediction.\n",
      "\n",
      "**Hazard-category:** other hazard\n",
      "**Product-category:** meat, egg and dairy products\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The title of the recall report is \"Woolworths Limited—Regular Beef Mince\", which indicates that the product category is related to meat.\n",
      "* The text mentions \"Beef Mince\" and \"Meat Departments\", further confirming that the product category is indeed \"meat, egg and dairy products\".\n",
      "* There's no mention of any specific hazard such as allergens, biological, chemical, etc. in\n",
      "\n",
      "Parse OK: 13 / 30 = 0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "run_rag_debug(valid_df, k_h=3, k_p=3, max_rows=30, show_fail=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3a756-bb6b-4fb9-b5b3-a0dda5dab98e",
   "metadata": {},
   "source": [
    "## All VAL DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "433edaf9-db10-415a-90d9-07b4dd06095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 565/565 [29:34<00:00,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parse_ok_rate': 0.9964601769911504, 'n_total': 565, 'n_parse_ok': 563, 'hazard': {'acc': 0.4955595026642984, 'macro_f1': 0.30624548848461136, 'micro_f1': 0.4955595026642984, 'weighted_f1': 0.5391691880819212}, 'product': {'acc': 0.42984014209591476, 'macro_f1': 0.3741908438772263, 'micro_f1': 0.42984014209591476, 'weighted_f1': 0.4389399618492287}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "valid_df = pd.read_csv(\"incidents_valid.csv\").fillna(\"\")\n",
    "\n",
    "res_smoke = run_rag(valid_df, k_h=3, k_p=3)\n",
    "print(res_smoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54ca49ec-daaa-4aa3-9679-8573a6ce9933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 565/565 [27:54<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== VALID RAG (k=1) ====\n",
      "Hazard Macro-F1: 0.3018350904605418\n",
      "Product Macro-F1: 0.3387472056752452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 565/565 [31:05<00:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== VALID RAG (k=5) ====\n",
      "Hazard Macro-F1: 0.30001552429629924\n",
      "Product Macro-F1: 0.3919217574828468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [1,5]:\n",
    "    res = run_rag(valid_df, k_h=k, k_p=k)\n",
    "    print(\"\\n==== VALID RAG (k=%d) ====\" % k)\n",
    "    print(\"Hazard Macro-F1:\", res[\"hazard\"][\"macro_f1\"])\n",
    "    print(\"Product Macro-F1:\", res[\"product\"][\"macro_f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70ab2f-a2db-488a-b30d-e637a105ac18",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2324e9c7-1916-4c48-baa2-6d011189c72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 997\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv(\"incidents_test.csv\").fillna(\"\")\n",
    "\n",
    "print(\"Test size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee4579a8-fbfe-473f-9f07-07fd62344d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 997/997 [54:37<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RAG (k=5): {'parse_ok_rate': 0.9859578736208626, 'n_total': 997, 'n_parse_ok': 983, 'hazard': {'acc': 0.49847405900305186, 'macro_f1': 0.2613990546167623, 'micro_f1': 0.49847405900305186, 'weighted_f1': 0.5405143627642336}, 'product': {'acc': 0.4577822990844354, 'macro_f1': 0.4132363729529004, 'micro_f1': 0.4577822990844354, 'weighted_f1': 0.4676560806127195}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Full RAG on TEST (best k from ablation)\n",
    "res_test_rag_k5 = run_rag(test_df, k_h=5, k_p=5)\n",
    "print(\"TEST RAG (k=5):\", res_test_rag_k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463bca9b-4be2-49dd-9701-2ab98e16a597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
